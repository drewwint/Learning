{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drewwint/Learning/blob/main/ab_hands_on.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzLvVchlNsMQ"
      },
      "source": [
        "# Lesson: Hands-on A/B test modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79gFRX5mNsMR"
      },
      "source": [
        "Now that we covered the intuition behind Bayesian modeling and sampling, let's roll up our sleeves and get to actual modeling. You remember the A/B test model? Of course you do! How could forget such a poetic model, taught by as seductive a voice as Thomas'?\n",
        "\n",
        "Well, let's imagine that we actually have to _do_ that analysis, and code up this model ourselves. How do we do that? I'll show you right now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEZ7FH22NsMR"
      },
      "source": [
        "In this lesson, you will learn about:\n",
        "\n",
        "1. Installing PyMC\n",
        "\n",
        "    - Why virtual environments are important\n",
        "    - Using conda\n",
        "    - Starting Jupyter Lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgxBigp7NsMR"
      },
      "source": [
        "2. Setting up the model\n",
        "\n",
        "    - Importing the data\n",
        "    - Coding up the A/B test model in PyMC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcVm61qzNsMS"
      },
      "source": [
        "3. Getting the plausible values\n",
        "\n",
        "    - Checking our prior\n",
        "    - Fitting the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFVFrgZFNsMS"
      },
      "source": [
        "4. Getting analytical\n",
        "    - Checking convergence\n",
        "    - Analyzing the results\n",
        "    - Checking update of beliefs\n",
        "    - Checking the model's predictions\n",
        "    - Visualizing the Bayesian workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6N-fYPQNsMT"
      },
      "source": [
        "5. Putting it together\n",
        "    - Writing a new model for A/B test\n",
        "    - Doing everything in one step\n",
        "    - See how easy it is to fit it\n",
        "    - Compare versions A and B\n",
        "    - Decide on the best version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw5eBb_ENsMT"
      },
      "source": [
        "6. Bonus `InferenceData` Cheatsheet\n",
        "    - What is ArviZ?\n",
        "    - What is `InferenceData`?\n",
        "    - Why is it useful?\n",
        "    - What are a model's dimensions and coordinates?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXexDxkaNsMU"
      },
      "source": [
        "Let's dive right into it and see how we define a model in PyMC and then perform inference! Are you as excited as I am??\n",
        "\n",
        "A word of caution: some parts will feel weird and unfamiliar. Don't worry exactly about what all this means just yet. Simply focus on identifying the big parts of the model. You'll have plenty of time to understand the rest throughout this course.\n",
        "\n",
        "Before anything though, let's install PyMC!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtrxRZRaNsMU"
      },
      "source": [
        "## Installing PyMC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot71pna6NsMU"
      },
      "source": [
        "As PyMC is an actively developed package, the best practices for installation can sometimes change, so the best resource to be up-to-date is to take a look at [the documentation](https://www.pymc.io/projects/docs/en/stable/installation.html).\n",
        "\n",
        "Let's go to the terminal to install PyMC in a brand new virtual environment on MacOS!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g95eZwqmNsMV"
      },
      "source": [
        "### Section recap\n",
        "\n",
        "- An environment is the set of tools used to create a reproducible computation environment.\n",
        "- Environments make your analyses reproducible.\n",
        "- Environments let you share code easily (like in this course ðŸ˜‰).\n",
        "- Environments save you headaches down the line.\n",
        "- Prefer conda to install PyMC -- the C compiler infrastructure will be taken care of for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC1K7CI-NsMV"
      },
      "source": [
        "## Setting up the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCZjNtHQNsMV"
      },
      "source": [
        "In this section, we'll amp up the ante and _code_ up the A/B test model. In other words, Thomas _told_ you how easy and useful Bayes is -- now I'm gonna _show_ you. I could also add that Bayesian stats are cool, but that would be redundant -- you saw how darn cool we are in the intro video...\n",
        "\n",
        "Ok, let's load the A/B test data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QACGILoNsMV"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcBQeWeRNsMW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url_control_signups = \"https://raw.githubusercontent.com/drewwint/Learning/refs/heads/main/Intuative_Bayes/IntroductoryCourse-main/IntroductoryCourse-main/lesson_code/3_AB_Hands_On/data/control-signups.csv\"\n",
        "signups = pd.read_csv(url_control_signups, index_col=0) #\"data/control-signups.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS50mjpzNsMW"
      },
      "source": [
        "And check out what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XDM3YBANsMW"
      },
      "outputs": [],
      "source": [
        "import arviz as az"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpAjA6GVNsMW"
      },
      "outputs": [],
      "source": [
        "az.style.use(\"arviz-darkgrid\")\n",
        "az.plot_dist(signups);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL5jLUvtNsMX"
      },
      "source": [
        "Just a note: we're using a library called ArviZ to make that plot. Keep it in mind, you'll use it throughout the course and get a more thorough introduction in the coming lesson. In short, ArviZ is useful for any Bayesian plot and to store and analyze the results of your Bayesian models.\n",
        "\n",
        "So, what can we make of this graph? Out of 100 people who saw our website, 8 of them clicked on the button (success), while 92 didn't do anything (failure) -- yes, the life of marketers is even harder than that of Dwayne Johnson's bathroom scale.\n",
        "\n",
        "But, if PyMC can't save that poor scale, it can save marketers! How? By doing all the heavy lifting for them!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV1N4DIKNsMX"
      },
      "source": [
        "### Coding up the PyMC model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH512pAWNsMX"
      },
      "source": [
        "Here is the full model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf6RgxJ7NsMX"
      },
      "outputs": [],
      "source": [
        "import pymc as pm\n",
        "\n",
        "with pm.Model() as model_signups:\n",
        "    # Parameter = prior solution space\n",
        "    conversion_rate = pm.Beta(\"conversion_rate\", alpha=2, beta=10)\n",
        "\n",
        "    # Plausibility evaluator: likelihood function\n",
        "    n_signups = pm.Binomial(\n",
        "        \"n_signups\", p=conversion_rate, n=len(signups), observed=signups.sum()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPGvdukZNsMX"
      },
      "source": [
        "Pretty simple, right?\n",
        "\n",
        "Now is actually time to test yourself:\n",
        "\n",
        "1. **Did you notice we changed likelihood here?**\n",
        "\n",
        "In the previous lesson, Thomas used a Bernoulli likelihood, for the sake of simplicity. But this is actually a particular case of the Binomial distribution, that we'll be using now.\n",
        "\n",
        "Why? There are several reasons, but the main one is that it matches the generative process more closely: we have 100 (`len(signups)`) binary trials (0s and 1s, i.e did the user sign up or not?), and those trials succeed with the probability `conversion_rate`, that we're trying to infer. It's like tossing a coin 100 times, counting how many times it landed on heads, and inferring whether the coin is fair or not. This describes _exactly_ a process that fits a Binomial distribution.\n",
        "\n",
        "Are you as lost as when you watched Matrix 4? Well, first of all, my condolences -- I'm sorry that you had to suffer through that movie. Second, don't worry, that's normal. I'm just giving you the high level view. Ravin will dive into more details in the next lesson.\n",
        "\n",
        "2. **What quantity are we really interested in with this model?**  \n",
        "\n",
        "`conversion_rate` (the `p` parameter of the Binomial), because it's an estimate of the true conversion rate, i.e what we're really after.\n",
        "\n",
        "3. **Do you remember what we do in the Bayesian framework when we don't know something?**\n",
        "\n",
        "As BeyoncÃ© would say: \"Just put a prior on it!\".\n",
        "\n",
        "4. **Finally, do you remember why we're using a Beta prior for `conversion_rate`?**\n",
        "\n",
        "Because it's a... conversion rate, as Captain Obvious would say! And the Beta family is perfect for this, as it spits out values only on the $[0, 1]$ interval. Again, I'm just telling you _why_ we're doing this -- you'll see the details in the coming lessons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ZZ429YNsMY"
      },
      "source": [
        "### Section recap\n",
        "\n",
        "- We imported the data and saw that we had 100 binary trials.\n",
        "- Therefore, we used a Binomial distribution for the data, and a Beta distribution for the Binomial's rate of success."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzJmFPVxNsMY"
      },
      "source": [
        "## Getting the plausible values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2AKqrjPNsMY"
      },
      "source": [
        "### Checking our assumptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiJsiG1ANsMY"
      },
      "source": [
        "Now, you may be wondering:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbJmobZ0NsMY"
      },
      "source": [
        "> But Alex, are you sure BeyoncÃ© said that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF6OnNB6NsMY"
      },
      "source": [
        "Good question. But I hope you're also wondering:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Nn9srANsMY"
      },
      "source": [
        "> How did you choose this exact Beta prior?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbi7oEh2NsMZ"
      },
      "source": [
        "You're not?? Well go ahead, ask yourself that. Go ahead, I'm waiting.\n",
        "\n",
        "Wow, _great_ question! In other words: **which conversion percentages is our model expecting before seeing any data?**\n",
        "\n",
        "As you'll learn later, this is called a prior predictive check, and it's very simple to do it with PyMC and ArviZ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkgAZPnFNsMZ"
      },
      "outputs": [],
      "source": [
        "with model_signups:\n",
        "    prior_samples = pm.sample_prior_predictive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_RzvFDeNsMZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ax = az.plot_dist(prior_samples.prior[\"conversion_rate\"])\n",
        "ax.set(\n",
        "    xlabel=\"Prior belief of conversion rate\", ylabel=\"Relative Plausibility\", title=\"Prior Check\"\n",
        ")\n",
        "plt.tick_params(left=False, labelleft=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccGthGlcNsMZ"
      },
      "source": [
        "This graph just tells us the percentages: before seeing any data, we expect our conversion rate to be between 0 and 0.6, with most of the probability mass until 0.3. That makes sense, right? Conversion rates are usually low.\n",
        "\n",
        "But **how many signups does our model expect before seeing any data?** In other words, how does our assumptions about conversion rates translate to actual signups (aka the data space)? Let's check, with the same kind of plot as above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMLd23l1NsMa"
      },
      "outputs": [],
      "source": [
        "ax = az.plot_dist(\n",
        "    prior_samples.prior_predictive[\"n_signups\"], hist_kwargs={\"alpha\": 0.8}\n",
        ")\n",
        "ax.set(\n",
        "    xlabel=\"Prior prediction of # of signups\",\n",
        "    ylabel=\"Relative Plausibility\",\n",
        "    title=\"Prior prediction of signups out of 100\",\n",
        ")\n",
        "plt.tick_params(left=False, labelleft=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZjWE-fZNsMa"
      },
      "source": [
        "This graph tells us the number of successes our model expects before being confronted to the real world. It does fit our domain knowledge: high number of signups are very rare, and a number of signups around 4 to 40 out of 100 trials (remember that the maximum is 100 here, the size of our data) seems reasonable.\n",
        "\n",
        "What if this graph didn't make sense? Well, we would try another prior (another Beta, or another distribution) for the conversion rate, or even another likelihood (that happens less often, but sometimes your choice of likelihood is ill-advised).\n",
        "\n",
        "But remember, Peter: with great power comes great responsibility. Oh no wait, that's for a movie I'm shooting soon. Where is the script for the Intuitive Bayes course? Ah, there it is!\n",
        "\n",
        "So, remember, Peter: **a likelihood is just a prior for the data, and priors are just assumptions, which means you can change them and test them however you want**. We'll saw that throughout the course.\n",
        "\n",
        "So what do we need to do now? Confront our model to the real world -- I know that's what you wanna do, you little scoundrel!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wpc5v6YNsMa"
      },
      "source": [
        "### Fitting the model to data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNSsjG4PNsMa"
      },
      "source": [
        "Now is the time to let our model see the data, and update our knowledge... if needed!\n",
        "\n",
        "PyMC's `sample` function does exactly that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3qDF2HQNsMa"
      },
      "outputs": [],
      "source": [
        "with model_signups:\n",
        "    # Posterior solution space\n",
        "    plausible_values = pm.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTb85AcINsMa"
      },
      "source": [
        "Now, I know what you're wondering:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dJjXa8YNsMa"
      },
      "source": [
        "> Why is it called PyMC, and not PyMCMC -- or $PyMC^2$?\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/Aausss8uUBIe3bZ3d2/giphy.gif\" style=\"margin:auto\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcfYY-iwNsMa"
      },
      "source": [
        "Just one \"MC\" doesn't make sense: does it stand for Markov Chain, or for Monte Carlo, and why???\n",
        "\n",
        "Believe me, I understand, but this is too much of a mystery to solve it right now.\n",
        "\n",
        "What we _can_ do is thinking back to that magic machine Thomas was talking about in the first lesson -- remember? Well here it is, it's `pm.sample`! Under the hood, guess what it's doing? Just counting, that's right -- albeit in a fancy way. Don't worry, we'll give you the intuition in the MCMC lesson.\n",
        "\n",
        "Here, in short, sampling worked seamlessly. We didn't get any warning and automatically got our results in the `plausible_values` object (which is an Arviz `InferenceData` object). In the next section, we'll explore our inferences. But first, let's recap!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ4JKrTtNsMa"
      },
      "source": [
        "### Section recap\n",
        "\n",
        "- We checked that our assumptions on the conversion rate (Beta distribution) fitted our domain knowledge.\n",
        "- We made sure the model didn't expect absurd signup numbers before seeing any data (prior predictive check).\n",
        "- We confronted our model and assumptions to the real world, by fitting it to the data (`pm.sample`).\n",
        "- The big object we got from `pm.sample` is called `InferenceData` and handled by ArviZ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spXdGbEZNsMa"
      },
      "source": [
        "_NB: we went very fast here. For more details and exploration of `InferenceData` magic, refer to the bonus section at the end of this lesson._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6KLOo2INsMa"
      },
      "source": [
        "## Getting analytical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lb6PSwNNsMa"
      },
      "source": [
        "Now that we have results, we want to know what the true conversion rate is! That's when we can use ArviZ functions, since `pm.sample` returns an `InferenceData` object by default."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JgDRZ86NsMa"
      },
      "source": [
        "### Did the model converge?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q41eYM4YNsMb"
      },
      "outputs": [],
      "source": [
        "az.summary(plausible_values, round_to=2, kind=\"stats\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxWd31jjNsMb"
      },
      "source": [
        "The summary is a quick way to glance at parameter estimates. That's normal if you don't understand all the columns for now. We'll see more summaries during the course.\n",
        "\n",
        "You can also refer to the accompanying video for a short explanation of the some of the columns, as well as to the [ArviZ documentation](https://arviz-devs.github.io/arviz/api/generated/arviz.summary.html).\n",
        "\n",
        "In practice though, summaries are not what you're gonna use most -- plots are much more useful and intuitive. One of the most common is the trace plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o97dsemNsMb"
      },
      "outputs": [],
      "source": [
        "az.plot_trace(plausible_values);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3svcOwJRNsMb"
      },
      "source": [
        "I'll explain how to interpret it in the linear regression lesson. For now, just consider that if the plot on the right (displaying all the iterations made by our sampler) looks like random noise (i.e there are no patterns), this is a very good sign."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO3masBiNsMc"
      },
      "source": [
        "### What are our results then??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDNz2GgYNsMc"
      },
      "source": [
        "Now, do you remember what we're after in this model? The conversion rate of the website, `conversion_rate` in our model. So what does the model say after seeing the data?\n",
        "\n",
        "We have a preview in the plot above, to the left, but that KDE is not very informative. There is a better way to visualize it in Arviz: the `plot_posterior` function! Since I know the true conversion rate (yes, I am _that_ smart, thank you), we'll plot it as a reference line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4JyI76mNsMc"
      },
      "outputs": [],
      "source": [
        "az.plot_posterior(plausible_values, ref_val=0.1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGph8tMqNsMc"
      },
      "source": [
        "Wait, wait, I know the face you're making!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v_DUawMNsMc"
      },
      "source": [
        "<img src=\"https://media.giphy.com/media/bqyck3FaMqOzqCrFQc/giphy.gif\" style=\"margin:auto\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnXq0ZZTNsMc"
      },
      "source": [
        "How do I know? That's the face _I_ make when my accountant tells me \"this transaction is eligible to the intra-European VAT reverse-charge mechanism\".\n",
        "\n",
        "Rest assured: unlike intra EU accounting, this plot will become way clearer (and cooler) once I explain it.\n",
        "\n",
        "Basically, the model is telling us that **the conversion rate is between 4% and 14%, with a 9% average and 94% probability**. Why 94%? Well, why not? Yeah, I hate it when people do that too -- come on, it's just a way to dodge the question!\n",
        "\n",
        "Here though, this answer _truly_ makes sense: you're used to 95% intervals -- but why? There is nothing magical about 95. If anything, [73 is much more magical](https://bigbangtheory.fandom.com/wiki/73)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT729cqWNsMc"
      },
      "source": [
        "Did you get the reference?\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/13Syr1nwDffUcw/giphy.gif\" style=\"margin:auto\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3h--cKQNsMd"
      },
      "source": [
        "The point is, in the Bayesian framework you can focus on any probability you want, because we're just counting the posterior samples respecting the given constraint -- remember Thomas' introductory lesson? It's the same thing.\n",
        "\n",
        "So, by the same logic, as indicated in the plot, given our data and priors, the model considers that **there is an about 70% chance that the true conversion rate is below 10%, and an about 30% chance that it's above**.\n",
        "\n",
        "In short: our model was able to recover the true latent conversion rate, although with substantial uncertainty -- we only have 100 samples after all!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp8GrVb5NsMd"
      },
      "source": [
        "### Did we update our beliefs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4VTXxzpNsMd"
      },
      "source": [
        "Are we wiser than before confronting the model to data though? In other words: did we update our assumptions about possible true conversion rates after observing conversion data?\n",
        "\n",
        "The `az.plot_dist_comparison` answers exactly that question.\n",
        "\n",
        "_NB: The `extend` function below is just a nice way to combine several `InferenceData` objects together -- e.g prior predictive, posterior and posterior predictive samples._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CE91XAqrNsMd"
      },
      "outputs": [],
      "source": [
        "with model_signups:\n",
        "    plausible_values.extend(prior_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbkIY09zNsMd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.ticker as mtick\n",
        "\n",
        "axes = az.plot_dist_comparison(plausible_values)  # that's the line that counts\n",
        "for ax in axes.ravel():\n",
        "    ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
        "    ax.set_ylabel(\"Plausibility\")\n",
        "plt.setp(axes, yticks=[]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wX737wRNsMd"
      },
      "source": [
        "So yeah, our beliefs about the conversion rate were clearly updated by the data -- they are much more narrow now.\n",
        "\n",
        "But, same question as when we looked at the prior:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7EetNxpNsMd"
      },
      "source": [
        "> Alex, are you really sure that BeyoncÃ© said that??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LawBJ0tLNsMd"
      },
      "source": [
        "Will you stop with BeyoncÃ© already?! _I_ don't know, _you_ don't know, _we_ will never know -- as Thomas told you, to be good Bayesians, you need to get comfortable with uncertainty!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwEsHj3tNsMd"
      },
      "source": [
        "### Does the model make good predictions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3hFLCRPNsMd"
      },
      "source": [
        "So, the real question is:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOmhGMsXNsMe"
      },
      "source": [
        "> Is this model any good?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9MWXVmUNsMe"
      },
      "source": [
        "Does updating our beliefs translate into better predictions?\n",
        "\n",
        "Good news: simulating future possible observations is just one more line of code in PyMC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqZhLNlKNsMe"
      },
      "outputs": [],
      "source": [
        "with model_signups:\n",
        "    posterior_predictives = pm.sample_posterior_predictive(plausible_values)\n",
        "    plausible_values.extend(posterior_predictives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGiGKH03NsMe"
      },
      "source": [
        "You may have guessed it: this is called a **posterior predictive check**, and we'll see a lot of them in the course.\n",
        "\n",
        "For now, let's plot those future _possible_ observations, and overlay the _real_ observations on top of them. As a bonus, I also plotted the prior predictions. That way, you can see how updating our beliefs translates into better predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDD26pxSNsMe"
      },
      "outputs": [],
      "source": [
        "ax = az.plot_dist(\n",
        "    plausible_values.posterior_predictive[\"n_signups\"],\n",
        "    label=\"Posterior Predictive\",\n",
        ")\n",
        "ax.axvline(\n",
        "    plausible_values.observed_data[\"n_signups\"],\n",
        "    ls=\"--\",\n",
        "    lw=3,\n",
        "    color=\"orange\",\n",
        "    label=\"Observed data\",\n",
        ")\n",
        "az.plot_dist(\n",
        "    plausible_values.prior_predictive[\"n_signups\"],\n",
        "    label=\"Prior Predictive\",\n",
        "    color=\"black\",\n",
        "    hist_kwargs={\"alpha\": 0.1},\n",
        "    ax=ax,\n",
        ")\n",
        "ax.set(\n",
        "    xlabel=\"Posterior prediction of # of signups\",\n",
        "    ylabel=\"Relative Plausibility\",\n",
        "    title=\"Posterior prediction of signups out of 100\",\n",
        ")\n",
        "ax.legend()\n",
        "plt.tick_params(left=False, labelleft=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-00wAI6NsMe"
      },
      "source": [
        "I'd say that looks very good, doesn't it? The data we observed could have credibly been generated by our model, i.e by the process we're simulating.\n",
        "\n",
        "Do you still feel as confused as in Matrix 4? Don't worry, that's normal -- we went through a lot of concepts, and that was your first PyMC model! As you get exposed to more of those during the course (and probably rewatch some videos), your understanding will increase. By the way, this is where the comparison with Matrix 4 stops: the more you watch it, the less you understand it.\n",
        "\n",
        "But don't sell yourself short: as you'll see in details in the Linear Regression lesson, you already went through some parts of what's called the Bayesian workflow. Here it is:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFhWlaLdNsMf"
      },
      "source": [
        "#### The Bayesian worklow\n",
        "\n",
        "![workflow](https://github.com/drewwint/Learning/blob/main/Intuative_Bayes/IntroductoryCourse-main/IntroductoryCourse-main/lesson_code/3_AB_Hands_On/img/IB_Bayesian_workflow.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd3pDtZENsMf"
      },
      "source": [
        "We'll detail all these steps when we talk about linear regression, but this is going to be a handy reference throughout the course so keep it in mind. Actually, let's recap, following the workflow steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYE-WCo2NsMf"
      },
      "source": [
        "### Section recap\n",
        "\n",
        "- Gathered data and prior knowledge\n",
        "- Created our model to infer the conversion rate\n",
        "- Stated and checked our assumptions before seeing the data (`pm.sample_prior_predictive`)\n",
        "- Confronted our model to reality (`pm.sample`)\n",
        "- Estimated the conversion rate with PyMC\n",
        "- Double checked that we can trust the results (summary, trace plot...)\n",
        "- Simulated the future to evaluate our model's predictions (`pm.sample_posterior_predictive`)\n",
        "- Saw that the Bayesian workflow is super critical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mddsw1q9NsMf"
      },
      "source": [
        "## Putting it together -- the A/B test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrZzxhsbNsMf"
      },
      "source": [
        "Until now, we've only looked at one website. But in real life, we're often interested in comparing two versions of a website and choosing the most efficient one. That's usually called an A/B test.\n",
        "\n",
        "Let's imagine that the model we've fitted so far is for the **control** version of the website (A), i.e the version all users currently see. Therefore, to run our A/B test, we need a model for the **intervention** (B), where, for instance, we changed the color of the signup button.\n",
        "\n",
        "Let's load the data, and then what we need to do is just copy our previous model and change a few variable names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZdzLLU9NsMf"
      },
      "outputs": [],
      "source": [
        "signups_intervention = pd.read_csv(\"data/intervention-signups.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3fQVYfYNsMf"
      },
      "outputs": [],
      "source": [
        "with pm.Model() as model_signups_intervention:\n",
        "\n",
        "    conversion_rate = pm.Beta(\"conversion_rate\", alpha=2, beta=10)\n",
        "\n",
        "    n_signups_intervention = pm.Binomial(\n",
        "        \"n_signups_intervention\",\n",
        "        p=conversion_rate,\n",
        "        n=len(signups_intervention),\n",
        "        observed=signups_intervention.sum(),\n",
        "    )\n",
        "\n",
        "    plausible_values_intervention = pm.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1r8-dC3NsMf"
      },
      "source": [
        "We got out inference data output. How efficient is our B version inferred to be? Let's ask ArviZ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeOUpr7ANsMf"
      },
      "outputs": [],
      "source": [
        "az.plot_posterior(plausible_values_intervention);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2fCH0fQNsMf"
      },
      "source": [
        "Well this version of the website seems to convert much more! We can see that with both the mean and the distribution. Actually, let's plot the conversion of the version side by side. ArviZ has another useful plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G06IavvlNsMf"
      },
      "outputs": [],
      "source": [
        "az.plot_forest(\n",
        "    [plausible_values, plausible_values_intervention],\n",
        "    model_names=[\"Control\", \"Intervention\"],\n",
        "    combined=True,\n",
        "    figsize=(5, 3),\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGWdWcNxNsMf"
      },
      "source": [
        "Now we can definitely tell variant B is better!\n",
        "\n",
        "The conclusion is unambiguous here, but what if the difference was smaller and we wanted to compute the probability than B is better than A? Simple, we just count the cases when B's conversion rate is higher than A's!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwC0_f6wNsMg"
      },
      "outputs": [],
      "source": [
        "diff = (\n",
        "    plausible_values_intervention.posterior[\"conversion_rate\"]\n",
        "    - plausible_values.posterior[\"conversion_rate\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3HC3m1ENsMg"
      },
      "source": [
        "Here, the probability will be equal to one, as we can already see in the forest plot, but we can still plot the distribution of differences with ArviZ, and 0 as a reference line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdusrF_nNsMg"
      },
      "outputs": [],
      "source": [
        "az.plot_posterior(diff, ref_val=0);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLcspY1rNsMg"
      },
      "source": [
        "As expected, there is no doubt that our intervention is better than the control -- we should probably switch to that version, don't you think?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBIMrK-TNsMg"
      },
      "source": [
        "### Section recap\n",
        "\n",
        "- Coded up a new conversion rate model all in one step\n",
        "- Fit this model to data\n",
        "- Intuited that this version was more efficient\n",
        "- Checked that intuition with visual and mathematical comparisons\n",
        "- Confirmed once again that statistics is just counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHoKpMfPNsMg"
      },
      "source": [
        "## Lesson recap\n",
        "\n",
        "- PyMC helps you:\n",
        "    - focus on model building and improvement\n",
        "    - without having to code your own fitting algorithms\n",
        "- Coding and fitting a model in PyMC is straightforward.\n",
        "- ArviZ is your friend for all pre- and post-processing modeling steps.\n",
        "- ArviZ integrates well with PyMC.\n",
        "- `InferenceData` objects are ArviZ's main structure.\n",
        "    - They contain contain everything you need to check, save and reproduce your Bayesian analysis.\n",
        "- Bayesian analysis is done with multiple packages and PPLs.\n",
        "    - In this course, we mainly use PyMC, [ArviZ](https://python.arviz.org/en/stable/), [Matplotlib](https://matplotlib.org/), [NumPy](https://numpy.org/), [Scipy](https://scipy.org/), [Pandas](https://pandas.pydata.org/) and [Xarray](https://xarray.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGvtFKJMNsMg"
      },
      "source": [
        "## Bonus section (unrecorded): `InferenceData` Cheatsheet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6IvgjVLNsMg"
      },
      "source": [
        "In this lesson, we introduced a fundamental new object, the `InferenceData`. It stores everything and lets you reproduce and share your analysis with your best friends at the bar -- what, you don't talk about Bayes when you go partying??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFRtffqbNsMg"
      },
      "source": [
        "Concretely, `InferenceData` objects contain several groups, each of which is a multidimensional-labeled array with one or more data variables, as shown in the figure below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ET6FcHXNsMg"
      },
      "source": [
        "![InferenceDataStructure](https://github.com/drewwint/Learning/blob/main/Intuative_Bayes/IntroductoryCourse-main/IntroductoryCourse-main/lesson_code/3_AB_Hands_On/img/InferenceDataStructure.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9WNLAn5NsMh"
      },
      "source": [
        "The full schema specification can be found in [ArviZ's documentation](https://python.arviz.org/en/stable/schema/schema.html) and is useful to parse through.\n",
        "\n",
        "These groups contain data related to a specific collection such as _posterior_, _observed data_, or _sampler stats_ (sampler quantities like divergence, tree depth, and log likelihood).\n",
        "\n",
        "Don't worry about those technical terms for now, we'll teach you that in the \"MCMC for practitioners\" lesson. We just mention them here to give you a first exposure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzFrJ7ysNsMh"
      },
      "source": [
        "The two most important concepts you have to bear in mind when using `InferenceData` objects are _dimensions_ and _coordinates_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QhQnNn8NsMh"
      },
      "source": [
        "The **dimensions** of an object are its named axes. A variable containing 1D data will have dimensions `[chain, draw, dim0]`. Indeed the `chain` and `draw` dimensions are always there (this is the result of a fitted Bayesian model, remember?). And then the variables' dimensions are appended. Every dimension present in an `InferenceData` variable must share names with a coordinate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s72cOB4kNsMi"
      },
      "source": [
        "A **coordinate** is a named array that labels a dimension. For instance, a coordinate that will always be there will be... you guessed it, `chain`, whose values will be `[0, 1, 2, 3]` if you ran 4 chains. And this coordinate labels the `chain` dimension we saw above. In other words, coordinate names and values can be loosely thought of as labels and their corresponding tick labels along a dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSI-sOFlNsMi"
      },
      "source": [
        "We know this sounds dry, as any new concept. Just let it think sink in; you will get it, with time and repeated exposure.\n",
        "\n",
        "Actually, a way to jumpstart your understanding of the wonderfulness of `InferenceData` is just to play around with it. In the following cells, you will find a sample of the most useful functions to operate with `InferenceData` objects.\n",
        "\n",
        "**This section is not accompanied by a video because it is not mandatory to understand this lesson**. But if you're curious, we encourage you to play around with the code below. You can also use it as a cheatsheet to reuse in your own analysis. This will surely accelerate your understanding of future lessons, and improve your own code.\n",
        "\n",
        "Happy exploring!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6ZzySeMNsMi"
      },
      "outputs": [],
      "source": [
        "plausible_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lnt_pswJNsMi"
      },
      "outputs": [],
      "source": [
        "# access a group\n",
        "plausible_values.posterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYHmKxvXNsMi"
      },
      "outputs": [],
      "source": [
        "# combine chains and draws\n",
        "plausible_values.posterior.stack(sample=(\"chain\", \"draw\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBYOjA6-NsMj"
      },
      "outputs": [],
      "source": [
        "# obtain a numpy array for a given parameter:\n",
        "plausible_values.posterior[\"conversion_rate\"].data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYkDBKKeNsMj"
      },
      "outputs": [],
      "source": [
        "# mean along all dimensions\n",
        "plausible_values.posterior.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxMZJWFiNsMj"
      },
      "outputs": [],
      "source": [
        "# specify along which dimension\n",
        "plausible_values.posterior.mean(\"draw\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo_5VGD0NsMj"
      },
      "outputs": [],
      "source": [
        "# any summary function\n",
        "plausible_values.posterior.quantile(q=[0.25, 0.5, 0.75], dim=(\"chain\", \"draw\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEeaHR1mNsMj"
      },
      "source": [
        "For more details, you can take a look at the [getting started guide](https://python.arviz.org/en/stable/getting_started/index.html) on ArviZ website."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGSk6ceNsMj"
      },
      "source": [
        "### Section recap\n",
        "\n",
        "- `pm.sample` returns an `InferenceData` object.\n",
        "- ArviZ uses it to tidy up and organize the results.\n",
        "- We use ArviZ to:\n",
        "    - criticize and compare models\n",
        "    - plot the results\n",
        "- The HTML repr is very useful for debugging.\n",
        "- All groups can be accessed programatically.\n",
        "- You can use any summary function and specify on which dimension/coordinate."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Diaporama",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}